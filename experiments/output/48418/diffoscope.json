{"diffoscope-json-version": 1, "source1": "first/StrTokenizer.class", "source2": "second/StrTokenizer.class", "unified_diff": null, "details": [{"source1": "procyon -ec {}", "source2": "procyon -ec {}", "unified_diff": "@@ -22,14 +22,29 @@\n     private StrMatcher delimMatcher;\n     private StrMatcher quoteMatcher;\n     private StrMatcher ignoredMatcher;\n     private StrMatcher trimmerMatcher;\n     private boolean emptyAsNull;\n     private boolean ignoreEmptyTokens;\n     \n+    static {\n+        (CSV_TOKENIZER_PROTOTYPE = new StrTokenizer()).setDelimiterMatcher(StrMatcher.commaMatcher());\n+        StrTokenizer.CSV_TOKENIZER_PROTOTYPE.setQuoteMatcher(StrMatcher.doubleQuoteMatcher());\n+        StrTokenizer.CSV_TOKENIZER_PROTOTYPE.setIgnoredMatcher(StrMatcher.noneMatcher());\n+        StrTokenizer.CSV_TOKENIZER_PROTOTYPE.setTrimmerMatcher(StrMatcher.trimMatcher());\n+        StrTokenizer.CSV_TOKENIZER_PROTOTYPE.setEmptyTokenAsNull(false);\n+        StrTokenizer.CSV_TOKENIZER_PROTOTYPE.setIgnoreEmptyTokens(false);\n+        (TSV_TOKENIZER_PROTOTYPE = new StrTokenizer()).setDelimiterMatcher(StrMatcher.tabMatcher());\n+        StrTokenizer.TSV_TOKENIZER_PROTOTYPE.setQuoteMatcher(StrMatcher.doubleQuoteMatcher());\n+        StrTokenizer.TSV_TOKENIZER_PROTOTYPE.setIgnoredMatcher(StrMatcher.noneMatcher());\n+        StrTokenizer.TSV_TOKENIZER_PROTOTYPE.setTrimmerMatcher(StrMatcher.trimMatcher());\n+        StrTokenizer.TSV_TOKENIZER_PROTOTYPE.setEmptyTokenAsNull(false);\n+        StrTokenizer.TSV_TOKENIZER_PROTOTYPE.setIgnoreEmptyTokens(false);\n+    }\n+    \n     private static StrTokenizer getCSVClone() {\n         return (StrTokenizer)StrTokenizer.CSV_TOKENIZER_PROTOTYPE.clone();\n     }\n     \n     public static StrTokenizer getCSVInstance() {\n         return getCSVClone();\n     }\n@@ -506,23 +521,8 @@\n     @Override\n     public String toString() {\n         if (this.tokens == null) {\n             return \"StrTokenizer[not tokenized yet]\";\n         }\n         return \"StrTokenizer\" + this.getTokenList();\n     }\n-    \n-    static {\n-        (CSV_TOKENIZER_PROTOTYPE = new StrTokenizer()).setDelimiterMatcher(StrMatcher.commaMatcher());\n-        StrTokenizer.CSV_TOKENIZER_PROTOTYPE.setQuoteMatcher(StrMatcher.doubleQuoteMatcher());\n-        StrTokenizer.CSV_TOKENIZER_PROTOTYPE.setIgnoredMatcher(StrMatcher.noneMatcher());\n-        StrTokenizer.CSV_TOKENIZER_PROTOTYPE.setTrimmerMatcher(StrMatcher.trimMatcher());\n-        StrTokenizer.CSV_TOKENIZER_PROTOTYPE.setEmptyTokenAsNull(false);\n-        StrTokenizer.CSV_TOKENIZER_PROTOTYPE.setIgnoreEmptyTokens(false);\n-        (TSV_TOKENIZER_PROTOTYPE = new StrTokenizer()).setDelimiterMatcher(StrMatcher.tabMatcher());\n-        StrTokenizer.TSV_TOKENIZER_PROTOTYPE.setQuoteMatcher(StrMatcher.doubleQuoteMatcher());\n-        StrTokenizer.TSV_TOKENIZER_PROTOTYPE.setIgnoredMatcher(StrMatcher.noneMatcher());\n-        StrTokenizer.TSV_TOKENIZER_PROTOTYPE.setTrimmerMatcher(StrMatcher.trimMatcher());\n-        StrTokenizer.TSV_TOKENIZER_PROTOTYPE.setEmptyTokenAsNull(false);\n-        StrTokenizer.TSV_TOKENIZER_PROTOTYPE.setIgnoreEmptyTokens(false);\n-    }\n }\n"}]}
